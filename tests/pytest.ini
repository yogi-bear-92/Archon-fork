[tool:pytest]
# Pytest configuration for Archon with comprehensive Serena Master Agent testing

# Test discovery
testpaths = python/tests
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*

# Markers for test categorization and filtering
markers =
    # Core test categories
    unit: Unit tests for individual components
    integration: Integration tests for component interactions
    e2e: End-to-end tests for complete workflows
    performance: Performance and benchmarking tests
    load: Load tests for enterprise-scale scenarios
    slow: Slow-running tests (skipped in quick runs)
    
    # Serena-specific markers
    serena: Tests for Serena Master Agent functionality
    semantic_analysis: Semantic analysis capability tests
    coordination: Agent coordination and communication tests
    memory_management: Memory persistence and context tests
    mcp_tools: MCP tool integration tests
    
    # Test environment markers
    mock: Tests using mock objects and simulations
    real_system: Tests requiring real system components
    concurrent: Tests involving concurrent operations
    
    # Test priority markers
    critical: Critical functionality tests (always run)
    regression: Regression prevention tests
    smoke: Quick smoke tests for basic functionality
    
    # Platform-specific markers
    requires_network: Tests requiring network access
    requires_db: Tests requiring database access
    requires_filesystem: Tests requiring filesystem access

# Test execution configuration
addopts = 
    # Verbose output with detailed test names
    -v
    
    # Show local variables in tracebacks
    --tb=short
    
    # Enable strict marker checking
    --strict-markers
    
    # Show warnings
    -r A
    
    # Disable cacheprovider for consistent test isolation
    --cache-clear
    
    # Async test support
    --asyncio-mode=auto
    
    # Coverage reporting (optional, uncomment if desired)
    # --cov=src
    # --cov-report=html
    # --cov-report=term-missing
    # --cov-fail-under=80
    
    # Performance test timing
    --durations=10
    
    # Parallel execution (uncomment for faster test runs)
    # -n auto
    
    # Filter out deprecation warnings from dependencies
    --disable-warnings

# Test timeout configuration
timeout = 300
timeout_method = thread

# Async test configuration
asyncio_mode = auto

# Test collection filtering
collect_ignore = [
    "setup.py",
    "node_modules",
    ".git",
    "__pycache__",
    "*.egg-info",
    "build",
    "dist"
]

# Minimum version requirements
minversion = 6.0

# Test filtering patterns
filterwarnings = 
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::UserWarning:pytest_asyncio
    ignore::RuntimeWarning

# Log configuration for test debugging
log_cli = false
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# File logging during tests
log_file = tests/logs/pytest.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] %(filename)s:%(lineno)d: %(message)s
log_file_date_format = %Y-%m-%d %H:%M:%S

# Test result reporting
junit_family = xunit2
junit_logging = system-out

# Custom test selection expressions for common use cases
# Run with: pytest -m "marker_expression"
# 
# Examples:
#   pytest -m "serena and unit"           # Serena unit tests only
#   pytest -m "not slow"                  # Skip slow tests
#   pytest -m "critical or smoke"         # Critical and smoke tests
#   pytest -m "serena and performance"    # Serena performance tests
#   pytest -m "integration and not load"  # Integration tests excluding load tests